

**Given here are the datasets that you can work on for the competetion.**
5 datasets.5 separate folders.
Open each folder to view the description of each dataset and the prediction task that you have to perform on the dataset.
No separate training and testing data are available.You have to divinde the data file separately into training and testing data in 7:3 ratio.
# Rules
1. You have to perform the data analysis in Jupyter Notebook(Python).The team has to upload their notebook after the time ends.
2. You hav 6 hours to perform the required analysis.
3. After 3 hours submit your testing data by uploading on your git and sharing the git link.
4. We expect original code.As each analysis is unique.If we find out that you have copied the source code from the web you shall be disqualified immediately.We also have your own plagiarism checker. Feel free to use it :P. 
    **https://github.com/adityakulraj/plagiarismchecker**
5. After the time is up you need to upload your source code with a required explaination of how you have performed the analysis in a text document.
6.Uplaod all the required graphs with description in the text document.
7. You need to comment the description of each library used.
8. Your model will be evaluated on the basis of Accuracy,Precision, F-measure and ROC Curve.
9.The accuaracy measure shouldn't be very high as that will lead to an overfitted model.
10.The decision of the Qrganizers is final and binding.



## Judgement Criteria

### 1. Data Preprocessing 
How you preprocess the data for input into the model.Involves removing null values, vectorization, serialization , binarisation etc.Tuning of Parameters wherever necessary is expected.The pre-processing of your code should be well commented and justified.You need to upload the processed data-set in the format which was given to you.If .csv then upload the processed file in .csv.If .json then .json.
You should also consider removing outliers and sensetive data.Proper description and visulation of outliers using boxplots and charts is expected.
**Make it as visual as you can using graphs(For ex. Seaborn library)** and justify why you performed the given technique for preprocessing.You also need to divide the dataset in training and testing in 7:3 ratio respectively.After 3 hours every team must upload their testing dataset for us to evaluate.



### 2. Model Building
After building your training data, you need to use a modelling algorithm to make your predictions.You need to justify as to why you have used that particular algorithm in the text document.


### 3. Evaluation
Your model will be evaluated on the basis of Accuracy,Precision, F-measure and ROC Curve.The accuaracy measure shouldn't be very high as that will lead to an overfitted model.We will run your model on your training set and find out the accuracy measures.**Do not overfit**.Accuracy above 95% is not desirable.Try to keep it in the range on (85-95)%.Your confusion matrix must be prepared from the testing data only.











